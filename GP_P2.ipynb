{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5a862fa755b339cb269ec5ceb6e73837f63b6953002ae94843c7ff6941dd7636"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from gtfparse import read_gtf\n",
    "import csv\n",
    "import io\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "VCF_HEADER = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "\n",
    "\n",
    "def dataframe(filename, large=True):\n",
    "    \"\"\"Open an optionally gzipped VCF file and return a pandas.DataFrame with\n",
    "    each INFO field included as a column in the dataframe.\n",
    "    Note: Using large=False with large VCF files. It will be painfully slow.\n",
    "    :param filename:    An optionally gzipped VCF file.\n",
    "    :param large:       Use this with large VCF files to skip the ## lines and\n",
    "                        leave the INFO fields unseparated as a single column.\n",
    "    \"\"\"\n",
    "    if large:\n",
    "        # Set the proper argument if the file is compressed.\n",
    "        comp = 'gzip' if filename.endswith('.gz') else None\n",
    "        # Count how many comment lines should be skipped.\n",
    "        comments = _count_comments(filename)\n",
    "        # Return a simple DataFrame without splitting the INFO column.\n",
    "        return pd.read_table(filename, compression=comp, skiprows=comments,\n",
    "                             names=VCF_HEADER, usecols=range(8))\n",
    "\n",
    "    # Each column is a list stored as a value in this dict. The keys for this\n",
    "    # dict are the VCF column names and the keys in the INFO column.\n",
    "    result = OrderedDict()\n",
    "    # Parse each line in the VCF file into a dict.\n",
    "    for i, line in enumerate(lines(filename)):\n",
    "        for key in line.keys():\n",
    "            # This key has not been seen yet, so set it to None for all\n",
    "            # previous lines.\n",
    "            if key not in result:\n",
    "                result[key] = [None] * i\n",
    "        # Ensure this row has some value for each column.\n",
    "        for key in result.keys():\n",
    "            result[key].append(line.get(key, None))\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "def lines(filename):\n",
    "    \"\"\"Open an optionally gzipped VCF file and generate an OrderedDict for\n",
    "    each line.\n",
    "    \"\"\"\n",
    "    fn_open = gzip.open if filename.endswith('.gz') else open\n",
    "\n",
    "    with fn_open(filename) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            else:\n",
    "                yield parse(line)\n",
    "\n",
    "\n",
    "def parse(line):\n",
    "    \"\"\"Parse a single VCF line and return an OrderedDict.\n",
    "    \"\"\"\n",
    "    result = OrderedDict()\n",
    "\n",
    "    fields = line.rstrip().split('\\t')\n",
    "\n",
    "    # Read the values in the first seven columns.\n",
    "    for i, col in enumerate(VCF_HEADER[:7]):\n",
    "        result[col] = _get_value(fields[i])\n",
    "\n",
    "    # INFO field consists of \"key1=value;key2=value;...\".\n",
    "    infos = fields[7].split(';')\n",
    "\n",
    "    for i, info in enumerate(infos, 1):\n",
    "        # info should be \"key=value\".\n",
    "        try:\n",
    "            key, value = info.split('=')\n",
    "        # But sometimes it is just \"value\", so we'll make our own key.\n",
    "        except ValueError:\n",
    "            key = 'INFO{}'.format(i)\n",
    "            value = info\n",
    "        # Set the value to None if there is no value.\n",
    "        result[key] = _get_value(value)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_value(value):\n",
    "    \"\"\"Interpret null values and return ``None``. Return a list if the value\n",
    "    contains a comma.\n",
    "    \"\"\"\n",
    "    if not value or value in ['', '.', 'NA']:\n",
    "        return None\n",
    "    if ',' in value:\n",
    "        return value.split(',')\n",
    "    return value\n",
    "\n",
    "\n",
    "def _count_comments(filename):\n",
    "    \"\"\"Count comment lines (those that start with \"#\") in an optionally\n",
    "    gzipped file.\n",
    "    :param filename:  An optionally gzipped file.\n",
    "    \"\"\"\n",
    "    comments = 0\n",
    "    fn_open = gzip.open if filename.endswith('.gz') else open\n",
    "    with fn_open(filename) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith('#'):\n",
    "                comments += 1\n",
    "            else:\n",
    "                break\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ID: chr22\nName: chr22\nDescription: chr22\nNumber of features: 0\nSeq('NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...NNN')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reading the fasta file (one record)\n",
    "OriginalSeq=[]\n",
    "seq_file = SeqIO.read(\"data/chr22.fa\", \"fasta\")\n",
    "print(seq_file)\n",
    "OriginalSeq=seq_file.seq\n",
    "\n",
    "seq_length=len(OriginalSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MutationsDf = dataframe(\"data/newmutations.vcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# De-crement indices by 1 for zero-index code\n",
    "MutationsDf.loc[:, \"POS\"] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'str'>\n<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "NewSequence = list(str(OriginalSeq))\n",
    "for i in range(len(MutationsDf)):\n",
    "    Position = MutationsDf['POS'].iloc[i]\n",
    "    NewSequence[Position] = MutationsDf['ALT'].iloc[i]\n",
    "NewSequence = \"\".join(NewSequence)\n",
    "\n",
    "print(type(NewSequence))\n",
    "print(type(str(OriginalSeq)))\n",
    "\n",
    "comparison1 = list(NewSequence)\n",
    "comparison2 = list(OriginalSeq)\n",
    "increment = 0\n",
    "\n",
    "for i in range(len(comparison1)):\n",
    "    if comparison1[i] != comparison2[i]:\n",
    "        increment += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'transcript_id', 'gene_type', 'gene_name', 'transcript_type', 'transcript_name', 'exon_number', 'exon_id', 'level', 'protein_id', 'transcript_support_level', 'hgnc_id', 'tag', 'ccdsid', 'havana_gene', 'havana_transcript']\n",
      "C:\\Users\\omars\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "df = read_gtf(\"data/newgeneannotations.gtf\")\n",
    "sorted_df = df.sort_values(by=[\"gene_name\", \"start\" , \"end\"])  # Sort by gene name, and then by start and end position ascendingly\n",
    "start_end_strand=sorted_df[[\"start\",\"end\",\"strand\",\"gene_name\",\"transcript_name\"]]\n",
    "\n",
    "# De-crement indices by 1 for zero-index code\n",
    "\n",
    "start_end_strand.loc[:, \"start\"] -= 1\n",
    "start_end_strand.loc[:, \"end\"] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Codontable = {\n",
    "    \"TTT\":\"Phe\", \"TTC\":\"Phe\", \"TTA\": \"Leu\", \"TTG\":\"Leu\",\n",
    "    \"CTT\":\"Leu\", \"CTC\":\"Leu\", \"CTA\": \"Leu\", \"CTG\":\"Leu\",\n",
    "    \"ATT\":\"Ile\", \"ATC\":\"Ile\", \"ATA\": \"Ile\", \"ATG\":\"Met\",\n",
    "    \"GTT\":\"Val\", \"GTC\":\"Val\", \"GTA\": \"Val\", \"GTG\":\"Val\",\n",
    "\n",
    "\n",
    "    \"TCT\":\"Ser\", \"TCC\":\"Ser\", \"TCA\": \"Ser\", \"TCG\":\"Ser\",\n",
    "    \"CCT\":\"Pro\", \"CCC\":\"Pro\", \"CCA\": \"Pro\", \"CCG\":\"Pro\",\n",
    "    \"ACT\":\"Thr\", \"ACC\":\"Thr\", \"ACA\": \"Thr\", \"ACG\":\"Thr\",\n",
    "    \"GCT\":\"Ala\", \"GCC\":\"Ala\", \"GCA\": \"Ala\", \"GCG\":\"Ala\",\n",
    "\n",
    "\n",
    "    \"TAT\":\"Tyr\", \"TAC\":\"Tyr\", \"TAA\": \"\",\"TAG\":\"\",\n",
    "    \"CAT\":\"His\", \"CAC\":\"His\", \"CAA\": \"Gln\", \"CAG\":\"Gln\",\n",
    "    \"AAT\":\"Asn\", \"AAC\":\"Asn\", \"AAA\": \"Lys\", \"AAG\":\"Lys\",\n",
    "    \"GAT\":\"Asp\", \"GAC\":\"Asp\", \"GAA\": \"Glu\", \"GAG\":\"Glu\",\n",
    "\n",
    "\n",
    "    \"TGT\":\"Cys\", \"TGC\":\"Cys\", \"TGA\": \"\",\"TGG\":\"Trp\",\n",
    "    \"CGT\":\"Arg\", \"CGC\":\"Arg\", \"CGA\": \"Arg\", \"CGG\":\"Arg\",\n",
    "    \"AGT\":\"Ser\", \"AGC\":\"Ser\", \"AGA\": \"Arg\", \"AGG\":\"Arg\",\n",
    "    \"GGT\":\"Gly\", \"GGC\":\"Gly\", \"GGA\": \"Gly\", \"GGG\":\"Gly\",\n",
    "    \"GGN\":\"Gly\", \"NNN\": \"XXX\"\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "CodonOneCodetable = {\n",
    "\n",
    "    \"Ala\": \"A\" , \"Arg\": \"R\" , \"Gly\": \"G\" ,\n",
    "    \"Asp\": \"D\" , \"Asx\": \"B\" , \"Cys\": \"C\" ,\n",
    "    \"Gln\": \"Q\" , \"Glu\": \"E\" , \"Asn\": \"N\" ,\n",
    "    \"Glx\": \"Z\" , \"Gly\": \"G\" , \"His\": \"H\" ,\n",
    "    \"Ile\": \"I\" , \"Leu\": \"L\" , \"Lys\": \"K\" ,\n",
    "    \"Met\": \"M\" , \"Phe\": \"F\" , \"Pro\": \"P\" ,\n",
    "    \"Ser\": \"S\" , \"Thr\": \"T\" , \"Trp\": \"W\" ,\n",
    "    \"Tyr\": \"Y\" , \"Val\": \"V\" , \"XXX\": \"X\" ,\n",
    "    \"\" : \"\" \n",
    "\n",
    "\n",
    "}\n",
    "MassTable = {\n",
    "    \"A\": 89 , \"R\": 174 , \"G\": 132 ,\n",
    "    \"D\": 133, \"B\": 133 , \"C\": 121 ,\n",
    "    \"Q\": 146 ,\"E\": 147 ,\"N\": 132  ,\n",
    "    \"Z\": 147, \"G\": 147 , \"H\": 155 ,\n",
    "    \"I\": 131, \"L\": 131 , \"K\": 146 ,\n",
    "    \"M\": 149, \"F\": 165 , \"P\": 115 ,\n",
    "    \"S\": 105, \"T\": 119 , \"W\": 204 ,\n",
    "    \"Y\": 181, \"V\": 117 , \"X\": 0 \n",
    "    \n",
    "}\n",
    "\n",
    "def TranslateManual(Sequence):\n",
    "\n",
    "    protein = \"\"\n",
    "    for i in range(0, len(Sequence) , 3):\n",
    "            codon = Sequence[i:i + 3]\n",
    "            if codon[2] == \"N\" or codon[1] == \"N\" or codon[0] == \"N\":\n",
    "                protein += \"X\"\n",
    "            else:\n",
    "                protein += CodonOneCodetable[Codontable[codon.upper()]]\n",
    "    return protein\n",
    "\n",
    "def CalculateMassManual(Sequence):\n",
    "    Sum = 0\n",
    "    for i in range(0, len(Sequence)):\n",
    "            protein = Sequence[i]\n",
    "            Sum += MassTable[protein]\n",
    "    return Sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Output_Dictionary_Mass(seq,start_end_strand):\n",
    "    Protein=[]\n",
    "    Gene_Region=[]\n",
    "    Dictionary = { \"Gene Seq\": [] , \"Protein Name\": [] , \"Protein Seq\" : [] , \"Mass\": [] }\n",
    "\n",
    "    for i in range(len(start_end_strand)):\n",
    "\n",
    "        if start_end_strand['strand'].iloc[i]==\"+\":\n",
    "            Gene_Region.append( str(seq[start_end_strand['start'].iloc[i]:start_end_strand['end'].iloc[i]]) )\n",
    "\n",
    "        elif start_end_strand['strand'].iloc[i]==\"-\":\n",
    "            Gene_Region.append( str( seq[start_end_strand['start'].iloc[i]:start_end_strand['end'].iloc[i]].reverse_complement() ) )\n",
    "\n",
    "        # Break condition\n",
    "        if i == len(start_end_strand)-1:\n",
    "            Merged_Gene_Region = ''.join(Gene_Region)  # Append all sequences of coding into 1 sequence\n",
    "\n",
    "            # Check for adding trailing N-sequence to make translation correct, is needed to make sequence divisible by 3\n",
    "            #--------------------------------\n",
    "            remainder = len(Merged_Gene_Region) % 3\n",
    "            if remainder != 0:\n",
    "                Merged_Gene_Region = Merged_Gene_Region + 'N' * (3 - remainder)\n",
    "            #------------------------------------------------------------\n",
    "            Merged_Gene_Region = Seq(Merged_Gene_Region)\n",
    "            #Protein=Merged_Gene_Region.translate(to_stop=True,cds=True)\n",
    "            Protein = TranslateManual(str(Merged_Gene_Region))\n",
    "\n",
    "\n",
    "            Dictionary[\"Protein Name\"].append(start_end_strand['gene_name'].iloc[i])\n",
    "            Dictionary[\"Protein Seq\"].append(Protein)\n",
    "            Dictionary[\"Gene Seq\"].append(Merged_Gene_Region)\n",
    "\n",
    "            #analysed_seq = ProteinAnalysis(str(Protein))\n",
    "            #Dictionary['Mass'].append(analysed_seq.molecular_weight())\n",
    "            massValue = CalculateMassManual(Protein)\n",
    "            Dictionary['Mass'].append(massValue)\n",
    "\n",
    "            Gene_Region = [ ] # Reset Gene_Region for new protein\n",
    "            Merged_Gene_Region = [ ]\n",
    "            break\n",
    "\n",
    "        # Translating Entire Gene Condition\n",
    "        if start_end_strand['gene_name'].iloc[i] != start_end_strand['gene_name'].iloc[i+1]:\n",
    "            Merged_Gene_Region = ''.join(Gene_Region)  # Append all sequences of coding into 1 sequence\n",
    "            \n",
    "            # Check for adding trailing N-sequence to make translation correct, is needed to make sequence divisible by 3\n",
    "            #--------------------------------\n",
    "            remainder = len(Merged_Gene_Region) % 3\n",
    "            if remainder != 0:\n",
    "                Merged_Gene_Region = Merged_Gene_Region + 'N' * (3 - remainder)\n",
    "            #------------------------------------------------------------\n",
    "            Merged_Gene_Region = Seq(Merged_Gene_Region)\n",
    "            #Protein=Merged_Gene_Region.translate(to_stop=True,cds=True)\n",
    "            Protein = TranslateManual(str(Merged_Gene_Region))\n",
    "\n",
    "\n",
    "\n",
    "            Dictionary[\"Protein Name\"].append(start_end_strand['gene_name'].iloc[i])\n",
    "            Dictionary[\"Protein Seq\"].append(Protein)\n",
    "            Dictionary[\"Gene Seq\"].append(Merged_Gene_Region)\n",
    "\n",
    "            #analysed_seq = ProteinAnalysis(str(Protein))\n",
    "            #Dictionary['Mass'].append(analysed_seq.molecular_weight())\n",
    "            massValue = CalculateMassManual(Protein)\n",
    "            Dictionary['Mass'].append(massValue)\n",
    "            \n",
    "            Gene_Region = [ ] # Reset Gene_Region for new protein\n",
    "            Merged_Gene_Region = [ ]\n",
    "\n",
    "    #     print(\"%0.2f\" % molecular_weight(Gene_Region,\"DNA\"))\n",
    "    #     Dictionary[\"Mass\"].append(\"%0.2f\" % molecular_weight(Gene_Region,\"DNA\")) #sha8ala bs el size bydrb\n",
    "    return Dictionary\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=pd.DataFrame.from_dict( Output_Dictionary_Mass(OriginalSeq,start_end_strand) )\n",
    "sorted_Data = Data.sort_values(by=[\"Mass\"] , ascending=False)\n",
    "\n",
    "NewData = pd.DataFrame.from_dict( Output_Dictionary_Mass(Seq(NewSequence),start_end_strand) )\n",
    "sorted_NewData = NewData.sort_values(by=[\"Mass\"] , ascending=False)\n",
    "\n",
    "sorted_NewData[\"MassDifference\"] = sorted_NewData[\"Mass\"] - sorted_Data[\"Mass\"]  # Adding a new column for Mass Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing two different CSVs (not required, just for visual difference)\n",
    "sorted_Data.to_csv(\"Output_P2_REF_Masses.csv\" , index = False)\n",
    "sorted_NewData.to_csv(\"Output_P2_ALT_Masses.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "massDifferencesList = list(sorted_NewData[\"MassDifference\"]) # As list to be used later\n",
    "\n"
   ]
  }
 ]
}